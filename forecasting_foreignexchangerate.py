# -*- coding: utf-8 -*-
"""Forecasting_ForeignExchangeRate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P8_D4H81yf8kEGPTo6mObp2sPtR8vrIK

# **Foreign Exchange Rate Prediction**

Mahade Mishuk

**Data:** The time seriese I use can be found at, https://data.humdata.org/dataset/ecb-fx-rates?force_layout=desktop. This dataset contains foreign exchange rates quoted by the European Central Bank (ECB), where all rates are converted relative to the USD (USD/x). This means the values represent the exchange rate between USD and other currencies, i.e., how much 1 USD is worth in terms of another currency (USD to x)

Overview of the dataset: \\
Date: The first column represents the date for which the exchange rates are provided. We got data from Januay 4th, 1999 to today (Updated data).

Exchange Rates: The remaining columns represent the exchange rates for various currencies relative to USD. Each number in these columns tells you how many units of a specific currency you can buy with 1 USD.

Missing Data: Some columns/cells have 0.0 values, which indicates either missing data or currencies that weren't available for that date.

**The main objecive of the project to build ML model that can predict foreign exchange rate for the future (next day or even 5 years later) with the highest accuracy.**

---

Methods were used


*   Deep Learning Model
  1.   Prophet
  2.   LSTM (Long Short-Term Memory)

*   Machine Learning Model
    1.   Random Forest

### **Data Preparation and Cleaning**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from prophet import Prophet
from prophet.plot import plot_plotly, plot_components_plotly
import tensorflow as tf
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.callbacks import EarlyStopping, ModelCheckpoint

data = pd.read_csv('ECB_FX_USD-base.csv')
#drop 1st row
data = data.drop(0)
data

data.shape

data['Date'] = pd.to_datetime(data['Date'])

"""## **Prophet Model**

### USD to Hungarian Forint

Just use a currency code (e.g. EUR for Euro), run the model and get the forecasting prediction. And also you can change the period of time you want to get forecast.
"""

df = data[['Date','HUF']]
p = Prophet()
df.columns = ['ds','y']

ProphetModel = p.fit(df)

futurePrediction = p.make_future_dataframe(periods=30,freq='D') #you can use any period of time e.g. 1 = 1day, 30=30days/1 month, 365=1year
forecast_Currrency = p.predict(futurePrediction)
forecast_Currrency.tail()
##look at the yhat value

"""Interactive graph of the output"""

plot_plotly(p, forecast_Currrency)

"""You can also see weekly, monthly, yealy trend"""

plot_components_plotly(p, forecast_Currrency)

"""## **LSTM (Long Short-Term Memory) Model**

### USD to Euro

LSTMs also use for time series forecasting because they can learn patterns very effectively from sequences of data.
"""

data = data.iloc[::-1].reset_index(drop=True)  # Reverse
data = data.set_index('Date')

scaler = MinMaxScaler()               #Normalize the data
scaled_data = scaler.fit_transform(data)

timeStep = 10                         # Number of time steps in each sequence
num_features = len(data.columns)      # Number of colums fetures

n = []
labels = []
for i in range(len(scaled_data) - timeStep):
    seq = scaled_data[i:i+timeStep]
    label = scaled_data[i+timeStep][data.columns.get_loc('EUR')]   #use column/currency name
    n.append(seq)
    labels.append(label)

sequences = np.array(n)
labels = np.array(labels)

#split test-train data
train_size = int(0.8 * len(sequences))                     #Split data; use the head (first 80%) for training, and the tail (last 20%) for testing
train_x, test_x = sequences[:train_size], sequences[train_size:]
train_y, test_y = labels[:train_size], labels[train_size:]

#Creating LSTM model
LSTMmodel = Sequential()

#LSTM layers and dropout
LSTMmodel.add(LSTM(units=128,input_shape=(train_x.shape[1],train_x.shape[2]),return_sequences=True))
LSTMmodel.add(LSTM(units=64, return_sequences=True))
LSTMmodel.add(LSTM(units=32, return_sequences=False))
LSTMmodel.add(Dropout(0.3))
LSTMmodel.add(Dropout(0.3))
LSTMmodel.add(Dropout(0.3))

#Adding dense output layer
LSTMmodel.add(Dense(units=1))

#Compiling the model
LSTMmodel.compile(optimizer='adam', loss='mean_squared_error')

#batch size
batch_size = 64

LSTMmodel.summary()

#callbacks
erlyStoping = EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=100)
checkPoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)

#Train the model
histry = LSTMmodel.fit(train_x, train_y,
                        epochs=100,                #Larger epochs for better training
                        batch_size=128,
                        validation_split=0.3,      # Use part of the training data as validation
                        callbacks=[erlyStoping, checkPoint])

#Evaluate the best model on the test set
BestModel = tf.keras.models.load_model('best_model.keras')
TestLoss = BestModel.evaluate(test_x, test_y)
print("Test Loss:", TestLoss)

# Plot training & validation loss
plt.plot(histry.history['loss'], label='Train Loss')
plt.plot(histry.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.show()

#Predictions and evaluation metrics
LSTMprediction = BestModel.predict(test_x)

#Inverse transform for original scale
Test_yCopy = np.repeat(test_y.reshape(-1, 1), num_features, axis=-1)  # Repeat for all features
TrueValue = scaler.inverse_transform(Test_yCopy)[:, data.columns.get_loc('EUR')]

#Predicted values
LSTMpredictionCopy = np.repeat(LSTMprediction, num_features, axis=-1)  # Repeat for all features
predictedValue = scaler.inverse_transform(LSTMpredictionCopy)[:, data.columns.get_loc('EUR')]

#Plotting predicted and actual values
plt.figure(figsize=(15, 6))
plt.plot(data.index[-1318:], TrueValue, label='Actual')
plt.plot(data.index[-1318:], predictedValue, label='Predicted')
plt.title('Prediction vs Actual')
plt.xlabel('Year')
plt.ylabel('EUR Rate (USD/EUR)')
plt.legend()
plt.show()

#Evaluating the LSTM model by calculating errors
mae = mean_absolute_error(test_y, LSTMprediction)
mse = mean_squared_error(test_y, LSTMprediction)
rmse = np.sqrt(mean_absolute_error(test_y, LSTMprediction))

print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)

"""## **Random Forest Model**

### USD to JPY (Japanese Yen)
"""

#ds = data.iloc[::-1].reset_index(drop=True)  # Reverse the dataset
ds = data.copy()
ds['JPY'] = pd.to_numeric(ds['JPY'], errors='coerce')

# Convert the "Date" column to datetime and set it as the index
#ds['Date'] = pd.to_datetime(ds['Date'])
#ds.set_index('Date', inplace=True)

currency = "JPY"
ds.plot.line(y=currency, use_index=True)
plt.xticks(rotation=60)
plt.figsize=(10, 6)
plt.xlabel('Date')
plt.ylabel(currency)
plt.title(f'Time Series of {currency}')
plt.show()

ds= ds[['JPY']]

ds['previousDayRate']=ds['JPY'].shift(+1)
ds['twoDaysEarlierRate']=ds['JPY'].shift(+2)
ds['threeDaysEarlierRate']=ds['JPY'].shift(+3)
ds=ds.dropna()
ds.head()

#creating Model
RandomForest = RandomForestRegressor(n_estimators=100,max_features=2, random_state=1)

x1, x2, x3, y = ds['previousDayRate'],ds['twoDaysEarlierRate'],ds['threeDaysEarlierRate'],ds['JPY']

x1, x2, x3, y = np.array(x1), np.array(x2), np.array(x3), np.array(y)

x1, x2, x3, y = x1.reshape(-1,1), x2.reshape(-1,1), x3.reshape(-1,1), y.reshape(-1,1)

X = np.concatenate((x1,x2,x3),axis=1)  #concatination of x1, x2, x3

print(X.shape)

#test-train split: Here last 30 samples used for testing and rest of them for training.
X_train, X_test, Y_train, Y_test = X[:-500], X[-500:], y[:-500], y[-500:]

RandomForest.fit(X_train,Y_train)
RFprediction = RandomForest.predict(X_test)

plt.rcParams["figure.figsize"] = (15,6)
plt.plot(RFprediction,label='Random_Forest_Predictions')
plt.plot(Y_test,label='Actual Rate')
plt.xlabel('Time')
plt.ylabel('Rate')
plt.legend(loc="upper left")
plt.show()

rmse = np.sqrt(mean_squared_error(RFprediction,Y_test))
print('Root Mean Squared Error (RMSE):',(rmse) )

"""**References**

Data: https://data.humdata.org/dataset/ecb-fx-rates?force_layout=desktop

Various Python libraries used, including TensorFlow, Prophet, and Scikit-learn.

**Note:** \\

The European Central Bank (ECB) keep updates this dataset daily basis. Download the updated dataset and use in the model.


"""

